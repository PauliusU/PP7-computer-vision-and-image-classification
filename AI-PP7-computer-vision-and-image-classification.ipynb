{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETaj7dxJ3HQ8"
   },
   "source": [
    "# AI-PP7 computer vision and image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "[![Open in Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PauliusU/PP7-computer-vision-and-image-classification/blob/master/AI-PP7-computer-vision-and-image-classification.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Problem statement and goals\n",
    "\n",
    "Project aims to train a model that can classify people as having Covid and not having Covid based on the images.\n",
    "\n",
    "Project uses [Covid-Chestxray-Dataset](https://github.com/ieee8023/covid-chestxray-dataset) and ChexPert Dataset mentioned in [this article](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7372265/) from PP7 requirements.\n",
    "\n",
    "Loading data in Google Colab was one of the biggest challenges. I've downloaded combined dataset from [DeepCovid](https://github.com/shervinmin/DeepCovid) repo which was also mentioned in the same article. Later on, I've upload the dataset to personal Google Drive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if notebook is running in Google Colab environment\n",
    "import sys\n",
    "\n",
    "IS_IN_COLAB = 'google.colab' in sys.modules\n",
    "print(IS_IN_COLAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ❗WARNING if running the notebook in Google Colab ❗ Cell below will ask for permission to access your personal Google Drive. I required some manual steps, but it reduces dataset download time to 0.\n",
    "\n",
    "Couple of semi-manual steps are needed to set up.\n",
    "\n",
    "1. Give permission to access Google Drive.\n",
    "2. Open this link to get the dataset: [DeepCovid dataset in Google Drive](https://drive.google.com/drive/folders/1NhP7oV3mPk4H9VS4eY3aN7rftGz6zFkw).\n",
    "3. Add the shared dataset folder to your personal Google Drive by clicking \"Add shortcut to Drive\" like shown in the picture below.\n",
    "   \n",
    "![Example](./assets/drive.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_IN_COLAB:\n",
    "    # If running in Google Colab, setup Google Drive to be able to access the dataset\n",
    "\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "    # Set paths do training and test data in Google Drive\n",
    "    train_data_path = \"/content/drive/MyDrive/DeepCovid/train\"\n",
    "    test_data_path = \"/content/drive/MyDrive/DeepCovid/test\"\n",
    "else:\n",
    "    # If running locally\n",
    "    train_data_path = \"./dataset/train\"\n",
    "    test_data_path = \"./dataset/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ❗WARNING❗ Running cell below takes substantial amount ot time. On my local machine it took 15-20 minutes. This is due to a fact that, transfer learning is not used for the cell below.\n",
    "\n",
    "Quick research indicated, that \n",
    "# A good starting point is the general architectural principles of the VGG models.\n",
    "# These are a good starting point because they achieved top performance in the ILSVRC 2014 competition and because the modular structure of the architecture is easy to understand and implement.\n",
    "# Also, I plan to use this particular pre-trained model later when we will implement transfer learning.\n",
    "# The architecture involves stacking convolutional layers with small 3×3 filters followed by a max pooling layer.\n",
    "# Together, these layers form a block, and these blocks can be repeated where the number of filters in each block is increased with the depth of the network such as 32, 64, 128, 256 for the first four blocks of the model.\n",
    "# We will choose a fixed image size of 200x200 pixels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oYBKGoudHQgO",
    "outputId": "c6386cf8-445a-433d-f83c-d116cfe9bba4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create base model\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dropout, MaxPooling2D, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu',\n",
    "              kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Next, we need to prepare the data.This involves first defining an instance of the ImageDataGenerator that will scale the pixel values to the range of 0-1.\n",
    "# Then iterators need to be prepared for both the train and test datasets. We can use the flow_from_directory() function on the data generator and create one iterator for each of the train/ and test/ directories.\n",
    "# Finally, we can create a plot of the history collected during training stored in the “history” directory returned from the call to fit_generator().\n",
    "\n",
    "\n",
    "diagnostic_plot_name = \"diagnostic_summary_plot.png\"\n",
    "\n",
    "\n",
    "def summarize_diagnostics(history):\n",
    "    plt.subplot(211)\n",
    "    plt.title('Cross Entropy Loss')\n",
    "    plt.plot(history.history['loss'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    plt.subplot(212)\n",
    "    plt.title('Classification Accuracy')\n",
    "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    plt.savefig(diagnostic_plot_name)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "mode = \"binary\"\n",
    "batch = 64\n",
    "size = (200, 200)\n",
    "epochs = 20\n",
    "\n",
    "\n",
    "def run_test_harness(model):\n",
    "    datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "    print('train')\n",
    "    train_it = datagen.flow_from_directory(\n",
    "        train_data_path, class_mode=mode, batch_size=batch, target_size=size)\n",
    "    print('test')\n",
    "    test_it = datagen.flow_from_directory(\n",
    "        test_data_path, class_mode=mode, batch_size=batch, target_size=size)\n",
    "    history = model.fit(train_it, steps_per_epoch=len(\n",
    "        train_it), validation_data=test_it, validation_steps=len(test_it), epochs=epochs, verbose=0)\n",
    "\n",
    "    _, acc = model.evaluate(test_it, steps=len(test_it), verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "\n",
    "    summarize_diagnostics(history)\n",
    "\n",
    "\n",
    "run_test_harness(define_model())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "glaZUUPqggqS",
    "outputId": "e3c1293f-3876-4fca-99f3-bb395d78d90a"
   },
   "outputs": [],
   "source": [
    "# Wow! I got 96%:) Did not expect such high accuracy on the very first run.\n",
    "# We can also check out the diagnostic summary.\n",
    "\n",
    "def get_diagnostic_summary() -> None:\n",
    "    \"\"\" Helper function to generate diagnostic plot \"\"\"\n",
    "    plt.figure()\n",
    "    if IS_IN_COLAB:\n",
    "        img = plt.imread(f\"/content/{diagnostic_plot_name}\")\n",
    "    else:\n",
    "        img = plt.imread(f\"./{diagnostic_plot_name}\")    \n",
    "    plt.imshow(img) \n",
    "    plt.show()\n",
    "\n",
    "get_diagnostic_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5div8XShi1uP",
    "outputId": "f1dec4c6-04dc-4c44-eaea-8774850e5030"
   },
   "outputs": [],
   "source": [
    "# WARNING! This one might also take a while to run. For me it took more than 1.5 hours.\n",
    "\n",
    "# We can see that the model has overfit the training dataset at about 1 or 2 epochs.\n",
    "# I'm satisfied with the result, but the model would benefit from a regularization technique, so let's add dropout.\n",
    "\n",
    "def define_model_with_dropout():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu',\n",
    "              kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Let's also increase the number of epochs to give the model more space for refinement.\n",
    "epochs = 50\n",
    "\n",
    "run_test_harness(define_model_with_dropout())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "f-ct3JfZ4W_D",
    "outputId": "ec234020-1773-4a8c-d54f-4559fe1af932"
   },
   "outputs": [],
   "source": [
    "# Get new diagnostics\n",
    "\n",
    "get_diagnostic_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l0v7g0UFtC-b"
   },
   "outputs": [],
   "source": [
    "# Well the accuracy dropped, and it seems that ovefitting occurred slightly later, on the 3-4 epoch.\n",
    "# This model would need way more tuning to reduce overfitting.\n",
    "\n",
    "# I think this will be enough. I planned to use transfer learning, but results are good, so I will leave it for next time.\n",
    "# My conclusion is that keras is the best AI framework. I really enjoy working with it. Everything is simple and straightforward, API is well documented and understandable.\n",
    "# I liked the project, it was interesting to work with images. Most of the time was spent figuring out how to best load data and then running the model.\n",
    "# I was very surprised by the first result, it was way higher than I expected. \n",
    "# I also began to see how much computing power is needed for real world AI applications - ~3000 image training took almost an hour."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "nAIjqDuVFnfD",
    "1g3URNZWFqlj",
    "imi0dVRoUvvF",
    "AVJBBfeEv9fb",
    "kIv0qmZW5GTs",
    "v5Grl-Qf5GUg"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('AI-PP7-computer-vision-and-image-classific-vfwK3Y1X')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7d0b73673683e1eba6674c74cf2a66958f7d71970e221e601952b6d195f2a3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
