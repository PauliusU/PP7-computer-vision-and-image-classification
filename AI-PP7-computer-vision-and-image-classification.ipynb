{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETaj7dxJ3HQ8"
   },
   "source": [
    "# AI-PP7 computer vision and image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "[![Open in Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PauliusU/PP7-computer-vision-and-image-classification/blob/master/AI-PP7-computer-vision-and-image-classification.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Problem statement and goals\n",
    "\n",
    "Project aims to train a model that can classify people as having Covid and not having Covid based on the images.\n",
    "\n",
    "Project uses [Covid-Chestxray-Dataset](https://github.com/ieee8023/covid-chestxray-dataset) and ChexPert Dataset mentioned in [this article](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7372265/) from PP7 requirements.\n",
    "\n",
    "Loading data was one of the biggest challenges. I've downloaded combined dataset from [DeepCovid](https://github.com/shervinmin/DeepCovid) repo which was also mentioned in the same article. Later on, I've upload the dataset to personal Google Drive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Google Drive setup to be able to access the dataset\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ❗WARNING❗ Cell above will ask for permission to access your personal Google Drive. \n",
    "\n",
    "Couple of semi-manual steps are needed to set up.\n",
    "\n",
    "1. Give permission to access Google Drive.\n",
    "2. Open this link to get the dataset: [DeepCovid dataset in Google Drive](https://drive.google.com/drive/folders/1NhP7oV3mPk4H9VS4eY3aN7rftGz6zFkw).\n",
    "3. Add share folder to your personal Google Drive by clicking \"Add shortcut to Drive\" like shown in the picture below.\n",
    "   \n",
    "![Example](./assets/drive.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths do training and test data in Google Drive\n",
    "train_data_path = \"/content/drive/MyDrive/DeepCovid/train\"\n",
    "test_data_path = \"/content/drive/MyDrive/DeepCovid/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oYBKGoudHQgO",
    "outputId": "c6386cf8-445a-433d-f83c-d116cfe9bba4"
   },
   "outputs": [],
   "source": [
    "# WARNING! This part does not yet use transfer learning and might take up to 40 min. to run.\n",
    "\n",
    "# Let's develop a baseline model.\n",
    "# A good starting point is the general architectural principles of the VGG models.\n",
    "# These are a good starting point because they achieved top performance in the ILSVRC 2014 competition and because the modular structure of the architecture is easy to understand and implement.\n",
    "# Also, I plan to use this particular pre-trained model later when we will implement transfer learning.\n",
    "# The architecture involves stacking convolutional layers with small 3×3 filters followed by a max pooling layer.\n",
    "# Together, these layers form a block, and these blocks can be repeated where the number of filters in each block is increased with the depth of the network such as 32, 64, 128, 256 for the first four blocks of the model.\n",
    "# We will choose a fixed image size of 200x200 pixels.\n",
    "\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dropout, MaxPooling2D, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# For some reason tensorflow imports show errors for me, but everything works, so we can just ignore them.\n",
    "\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\topt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# Next, we need to prepare the data.This involves first defining an instance of the ImageDataGenerator that will scale the pixel values to the range of 0-1.\n",
    "# Then iterators need to be prepared for both the train and test datasets. We can use the flow_from_directory() function on the data generator and create one iterator for each of the train/ and test/ directories.\n",
    "# Finally, we can create a plot of the history collected during training stored in the “history” directory returned from the call to fit_generator().\n",
    "\n",
    "diagnostic_plot_name = \"diagnostic_summary_plot.png\"\n",
    "\n",
    "def summarize_diagnostics(history):\n",
    "\tplt.subplot(211)\n",
    "\tplt.title('Cross Entropy Loss')\n",
    "\tplt.plot(history.history['loss'], color='blue', label='train')\n",
    "\tplt.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\tplt.subplot(212)\n",
    "\tplt.title('Classification Accuracy')\n",
    "\tplt.plot(history.history['accuracy'], color='blue', label='train')\n",
    "\tplt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "\tplt.savefig(diagnostic_plot_name)\n",
    "\tplt.close()\n",
    "\n",
    "mode = \"binary\"\n",
    "batch = 64\n",
    "size = (200, 200)\n",
    "epochs = 20\n",
    "\n",
    "def run_test_harness(model):\n",
    "  datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "  train_it = datagen.flow_from_directory(train_data_path, class_mode=mode, batch_size=batch, target_size=size)\n",
    "  test_it = datagen.flow_from_directory(test_data_path, class_mode=mode, batch_size=batch, target_size=size)\n",
    "  history = model.fit(train_it, steps_per_epoch=len(train_it), validation_data=test_it, validation_steps=len(test_it), epochs=epochs, verbose=0)\n",
    " \n",
    "  _, acc = model.evaluate(test_it, steps=len(test_it), verbose=0)\n",
    "  print('> %.3f' % (acc * 100.0))\n",
    "\n",
    "  summarize_diagnostics(history)\n",
    " \n",
    "run_test_harness(define_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "glaZUUPqggqS",
    "outputId": "e3c1293f-3876-4fca-99f3-bb395d78d90a"
   },
   "outputs": [],
   "source": [
    "# Wow! I got 96%:) Did not expect such high accuracy on the very first run.\n",
    "# We can also check out the diagnostic summary.\n",
    "\n",
    "plt.figure()\n",
    "img = plt.imread(f\"/content/{diagnostic_plot_name}\")\n",
    "plt.imshow(img) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5div8XShi1uP",
    "outputId": "f1dec4c6-04dc-4c44-eaea-8774850e5030"
   },
   "outputs": [],
   "source": [
    "# WARNING! This one might also take a while to run. For me it took more than 1.5 hours.\n",
    "\n",
    "# We can see that the model has overfit the training dataset at about 1 or 2 epochs.\n",
    "# I'm satisfied with the result, but the model would benefit from a regularization technique, so let's add dropout.\n",
    "\n",
    "def define_model_with_dropout():\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "  model.add(MaxPooling2D((2, 2)))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "  opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "# Let's also increase the number of epochs to give the model more space for refinement.\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "run_test_harness(define_model_with_dropout())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "f-ct3JfZ4W_D",
    "outputId": "ec234020-1773-4a8c-d54f-4559fe1af932"
   },
   "outputs": [],
   "source": [
    "# Let's look at the new diagnostics.\n",
    "\n",
    "plt.figure()\n",
    "img = plt.imread(f\"/content/{diagnostic_plot_name}\")\n",
    "plt.imshow(img) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l0v7g0UFtC-b"
   },
   "outputs": [],
   "source": [
    "# Well the accuracy dropped, and it seems that ovefitting occurred slightly later, on the 3-4 epoch.\n",
    "# This model would need way more tuning to reduce overfitting.\n",
    "\n",
    "# I think this will be enough. I planned to use transfer learning, but results are good, so I will leave it for next time.\n",
    "# My conclusion is that keras is the best AI framework. I really enjoy working with it. Everything is simple and straightforward, API is well documented and understandable.\n",
    "# I liked the project, it was interesting to work with images. Most of the time was spent figuring out how to best load data and then running the model.\n",
    "# I was very surprised by the first result, it was way higher than I expected. \n",
    "# I also began to see how much computing power is needed for real world AI applications - ~3000 image training took almost an hour."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "nAIjqDuVFnfD",
    "1g3URNZWFqlj",
    "imi0dVRoUvvF",
    "AVJBBfeEv9fb",
    "kIv0qmZW5GTs",
    "v5Grl-Qf5GUg"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "657b8203a0e8d62738f05adb8157364e4e4a718231ff4ced3525553e19b92b15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
