{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETaj7dxJ3HQ8"
   },
   "source": [
    "# AI-PP7 computer vision and image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "[![Open in Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PauliusU/PP7-computer-vision-and-image-classification/blob/master/AI-PP7-computer-vision-and-image-classification.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Problem statement and goals\n",
    "\n",
    "Project aims to train a model that can classify people as having Covid and not having Covid based on the images.\n",
    "\n",
    "Project uses [Covid-Chestxray-Dataset](https://github.com/ieee8023/covid-chestxray-dataset) and ChexPert Dataset mentioned in [this article](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7372265/) from PP7 requirements.\n",
    "\n",
    "Loading data in Google Colab was one of the biggest challenges. I've downloaded combined dataset from [DeepCovid](https://github.com/shervinmin/DeepCovid) repo which was also mentioned in the same article. Later on, I've upload the dataset to personal Google Drive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if notebook is running in Google Colab environment\n",
    "import sys\n",
    "\n",
    "IS_IN_COLAB = 'google.colab' in sys.modules\n",
    "print(IS_IN_COLAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is used\n",
    "import tensorflow as tf\n",
    "print(\"Number GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Print the list of available training devices - alternative method to verify TensorFlow sees the GPU\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ❗WARNING if running the notebook in Google Colab ❗ Cell below will ask for permission to access your personal Google Drive. I requires some manual steps, but it reduces dataset download time to 0.\n",
    "\n",
    "Couple of semi-manual steps are needed to set up.\n",
    "\n",
    "1. Give permission to access Google Drive.\n",
    "2. Open this link to get the dataset: [DeepCovid dataset in Google Drive](https://drive.google.com/drive/folders/1NhP7oV3mPk4H9VS4eY3aN7rftGz6zFkw).\n",
    "3. Add the shared dataset folder to your personal Google Drive by clicking \"Add shortcut to Drive\" like shown in the picture below.\n",
    "   \n",
    "![Example](./assets/drive.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_IN_COLAB:\n",
    "    # If running in Google Colab, setup Google Drive to be able to access the dataset\n",
    "\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "    # Set paths do training and test data in Google Drive\n",
    "    train_data_path = \"/content/drive/MyDrive/DeepCovid/train\"\n",
    "    test_data_path = \"/content/drive/MyDrive/DeepCovid/test\"\n",
    "else:\n",
    "    # If running locally\n",
    "    train_data_path = \"./dataset/train\"\n",
    "    test_data_path = \"./dataset/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup diagnostics to be later used for model analysis\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "diagnostic_plot_name = \"diagnostic_summary_plot.png\"\n",
    "\n",
    "\n",
    "def summarize_diagnostics(history):\n",
    "    plt.subplot(211)\n",
    "    plt.title('Cross Entropy Loss')\n",
    "    plt.plot(history.history['loss'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    plt.subplot(212)\n",
    "    plt.title('Classification Accuracy')\n",
    "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    plt.savefig(diagnostic_plot_name)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def get_diagnostic_summary() -> None:\n",
    "    \"\"\" Helper function to generate diagnostic plot \"\"\"\n",
    "    plt.figure()\n",
    "    if IS_IN_COLAB:\n",
    "        img = plt.imread(f\"/content/{diagnostic_plot_name}\")\n",
    "    else:\n",
    "        img = plt.imread(f\"./{diagnostic_plot_name}\")\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick research suggested that `VGG model` is good starting point due to modular structure of the architecture. Due to this, VGG model is relatively easy to understand and implement. In addition to that, it achieved top performance in the ILSVRC 2014 competition.\n",
    "\n",
    "For this model, a fixed image size of 200x200 pixels will be used. Several different sources proposed starting with stacking convolutional layers (Conv2D) with small 3×3 filters followed by a max pooling layer (MaxPooling2D). Together, these layers form a block, and these blocks can be repeated where the number of filters in each block is increased with the depth of the network such as 32, 64, 128, 256 for the first four blocks of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oYBKGoudHQgO",
    "outputId": "c6386cf8-445a-433d-f83c-d116cfe9bba4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a base model\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def define_model():\n",
    "    model = Sequential()\n",
    "    # Stacking convolutional layers with small 3×3 filters and image size of 200x200 pixels\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu',\n",
    "              kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further preparation consists of defining an ImageDataGenerator instance. It will scale the pixel values to the range of 0-1.\n",
    "Then iterators need to be prepared for both the train and test datasets. ImageDataGenerator's flow_from_directory function is use to create iterators for each of the directories (one for 'train', other for 'test').\n",
    "Eventually, we can create a plot of the history collected during training stored in the “history” directory returned from the call to fit_generator()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "mode = \"binary\"\n",
    "batch = 64\n",
    "size = (200, 200)\n",
    "epochs = 20\n",
    "\n",
    "def run_test_harness(model):\n",
    "    datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "    print('train')\n",
    "    train_iterator = datagen.flow_from_directory(\n",
    "        train_data_path, class_mode=mode, batch_size=batch, target_size=size)\n",
    "    print('test')\n",
    "    # Set iterators\n",
    "    test_iterator = datagen.flow_from_directory(\n",
    "        test_data_path, class_mode=mode, batch_size=batch, target_size=size)\n",
    "    history = model.fit(train_iterator, steps_per_epoch=len(\n",
    "        train_iterator), validation_data=test_iterator, validation_steps=len(test_iterator), epochs=epochs, verbose=0)\n",
    "\n",
    "    _, acc = model.evaluate(test_iterator, steps=len(test_iterator), verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "\n",
    "    summarize_diagnostics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ❗WARNING❗ Running code cell below takes substantial amount ot time. On my local machine it took 15-20 minutes. Transfer learning is not used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training time\n",
    "run_test_harness(define_model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interim result**: during my tests I constantly get accuracy of 97-98%. It exceeded my initial expectations. Let's see the diagnostic plot to to see more details what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "glaZUUPqggqS",
    "outputId": "e3c1293f-3876-4fca-99f3-bb395d78d90a"
   },
   "outputs": [],
   "source": [
    "# Generate diagnostic plot\n",
    "get_diagnostic_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intermediate conclusions: Plot indicates that the model is overfitting the training dataset somewhere at 1 or 2 epochs.\n",
    "\n",
    "As mentioned, earlier accuracy is already quite high (97-98%). However, let's see if the can improve the results by using a regularization technique, such as a dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ❗WARNING❗ Running code cell below takes even more time than the cell above. On my local machine it took about 30-45 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5div8XShi1uP",
    "outputId": "f1dec4c6-04dc-4c44-eaea-8774850e5030"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "\n",
    "def define_model_with_dropout():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu',\n",
    "              kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "epochs = 40  # Double the number of epochs from 20 to 40.\n",
    "\n",
    "run_test_harness(define_model_with_dropout())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "f-ct3JfZ4W_D",
    "outputId": "ec234020-1773-4a8c-d54f-4559fe1af932"
   },
   "outputs": [],
   "source": [
    "# Get new diagnostics\n",
    "get_diagnostic_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0v7g0UFtC-b"
   },
   "source": [
    "\n",
    "**Final result and conclusions**\n",
    "\n",
    "Tuning of model did not improve the results. In fact, in my tests accuracy dropped from 97-97% to 96%. Also, the plot suggests that that ovefitting is occurring slightly later (on the 3rd and 4th epoch). To reduce overfitting further tuning is needed.\n",
    "\n",
    "Implementing solution for this project clearly showed me how computing power-hungry AI projects could be. I was frustrated by the GPU limitations posed the Google Colab. Therefore, the initial cells includes logic for trining the downloaded dataset locally and checking if GPU is used at all. Combined dataset of ~5200 images proved to a though challenge for both Google Colab and my local environment. Running the notebook takes at least an hour or even more.\n",
    "\n",
    "This is the the transfer learning comes in. One of the main benefits of transfer learning includes the saving of resources and improved efficiency when training new models. I believe training performance would greatly benefit from it. However, given the surprisingly high initial accuracy, I've decided to leave transfer learning for the next time."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "nAIjqDuVFnfD",
    "1g3URNZWFqlj",
    "imi0dVRoUvvF",
    "AVJBBfeEv9fb",
    "kIv0qmZW5GTs",
    "v5Grl-Qf5GUg"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f5e382f1eed8daa9ac0994511ef297d7b436f72018668df1a3185f67b347eef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
